{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('processed_data_final.csv')\n",
    "X = data.drop(columns=['JobSatisfaction_O'])\n",
    "y = data['JobSatisfaction_O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_fixed_columns = [col for col in X.columns if col.endswith('_F') and X[col].dtype == 'float64']\n",
    "numerical_actionable_columns = [col for col in X.columns if col.endswith('_A') and X[col].dtype == 'float64']\n",
    "binary_fixed_columns = [col for col in X.columns if col.endswith('_F') and X[col].dtype == 'int64']\n",
    "binary_actionable_columns = [col for col in X.columns if col.endswith('_A') and X[col].dtype == 'int64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_actionable_groups = {}\n",
    "for col in binary_actionable_columns:\n",
    "    question_prefix = '_'.join(col.split('_')[:-2])\n",
    "    if question_prefix not in binary_actionable_groups:\n",
    "        binary_actionable_groups[question_prefix] = []\n",
    "    binary_actionable_groups[question_prefix].append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X[numerical_fixed_columns + numerical_actionable_columns] = scaler.fit_transform(X[numerical_fixed_columns + numerical_actionable_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_info = {\n",
    "    'numerical_fixed_columns': numerical_fixed_columns,\n",
    "    'numerical_actionable_columns': numerical_actionable_columns,\n",
    "    'binary_fixed_columns': binary_fixed_columns,\n",
    "    'binary_actionable_groups': binary_actionable_groups,\n",
    "    'scaler': scaler\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model with dropout layers\n",
    "class JobSatisfactionNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(JobSatisfactionNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.dropout1 = nn.Dropout(0.5)  # Dropout layer after the first fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)  # Dropout layer after the second fully connected layer\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)  # Applying dropout after activation\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)  # Applying dropout after activation\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JobSatisfactionNN(\n",
       "  (fc1): Linear(in_features=573, out_features=128, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "input_dim = X.shape[1]\n",
    "model = JobSatisfactionNN(input_dim)\n",
    "model.load_state_dict(torch.load('final_model.pth'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis(model, X, row_number, preprocessing_info, y):\n",
    "    original_data = X.iloc[row_number:row_number+1].copy()\n",
    "    original_tensor = torch.tensor(original_data.values, dtype=torch.float32)\n",
    "    original_job_satisfaction = y.iloc[row_number]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        original_prediction = model(original_tensor).item()\n",
    "\n",
    "    actionable_changes = []\n",
    "\n",
    "    # Numerical Actionable Features\n",
    "    for col in preprocessing_info['numerical_actionable_columns']:\n",
    "        min_value = X[col].min()\n",
    "        max_value = X[col].max()\n",
    "\n",
    "        for new_value in [min_value, max_value]:\n",
    "            modified_data = original_data.copy()\n",
    "            modified_data[col] = new_value\n",
    "            modified_tensor = torch.tensor(modified_data.values, dtype=torch.float32)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                modified_prediction = model(modified_tensor).item()\n",
    "\n",
    "            impact = modified_prediction - original_prediction\n",
    "            actionable_changes.append((col, original_data[col].values[0], new_value, original_prediction, modified_prediction, impact))\n",
    "\n",
    "    # Binary Actionable Features\n",
    "    for group, cols in preprocessing_info['binary_actionable_groups'].items():\n",
    "        for col in cols:\n",
    "            if original_data[col].values[0] == 1:\n",
    "                original_col = col\n",
    "                break\n",
    "        else:\n",
    "            original_col = None\n",
    "\n",
    "        for col in cols:\n",
    "            if col != original_col:\n",
    "                modified_data = original_data.copy()\n",
    "                if original_col:\n",
    "                    modified_data[original_col] = 0\n",
    "                modified_data[col] = 1\n",
    "                modified_tensor = torch.tensor(modified_data.values, dtype=torch.float32)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    modified_prediction = model(modified_tensor).item()\n",
    "\n",
    "                impact = modified_prediction - original_prediction\n",
    "                actionable_changes.append((col, original_data[col].values[0] if original_col else 0, 1, original_prediction, modified_prediction, impact))\n",
    "\n",
    "    actionable_changes.sort(key=lambda x: x[5], reverse=True)\n",
    "    return actionable_changes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: RemoteWork_Always_A, Original Answer: 0, New Answer: 1, Original Job Satisfaction: -0.2621, Predicted New Job Satisfaction: 0.1659, Impact: 0.4280\n",
      "Feature: MLMethodNextYearSelect_Factor Alysis_A, Original Answer: 0, New Answer: 1, Original Job Satisfaction: -0.2621, Predicted New Job Satisfaction: 0.0736, Impact: 0.3357\n",
      "Feature: MLToolNextYearSelect_TIBCO Spotfire_A, Original Answer: 0, New Answer: 1, Original Job Satisfaction: -0.2621, Predicted New Job Satisfaction: 0.0602, Impact: 0.3223\n",
      "Feature: MLToolNextYearSelect_RapidMiner (free version)_A, Original Answer: 0, New Answer: 1, Original Job Satisfaction: -0.2621, Predicted New Job Satisfaction: 0.0027, Impact: 0.2648\n",
      "Feature: LanguageRecommendationSelect_Stata_A, Original Answer: 0, New Answer: 1, Original Job Satisfaction: -0.2621, Predicted New Job Satisfaction: -0.0032, Impact: 0.2588\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "row_number = 1001  # Index of the new user\n",
    "top_changes = sensitivity_analysis(model, X, row_number, preprocessing_info, y)\n",
    "\n",
    "# Display top changes\n",
    "for change in top_changes:\n",
    "    print(f\"Feature: {change[0]}, Original Answer: {change[1]}, New Answer: {change[2]}, \"\n",
    "          f\"Original Job Satisfaction: {change[3]:.4f}, Predicted New Job Satisfaction: {change[4]:.4f}, \"\n",
    "          f\"Impact: {change[5]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextBlock(text='The most impactful change for improving job satisfaction is transitioning from the original \"No\" remote work policy to the new \"Yes\" remote work policy, which resulted in an increase of 0.4280 in job satisfaction, from an initial level of -0.2621 to an updated level of 0.1659.', type='text')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=os.getenv('ANTHROPIC_API_KEY')\n",
    ")\n",
    "\n",
    "# Assuming `top_changes` contains the top resulting changes from the sensitivity analysis\n",
    "top_change = top_changes[0]\n",
    "feature_name = top_change[0].replace('_', ' ').title()\n",
    "original_answer = \"Yes\" if top_change[1] == 1 else \"No\"\n",
    "new_answer = \"Yes\" if top_change[2] == 1 else \"No\"\n",
    "original_js = top_change[3]\n",
    "new_js = top_change[4]\n",
    "impact = top_change[5]\n",
    "\n",
    "# Construct the message to be rewritten in flowing English\n",
    "feature = feature_name\n",
    "original = original_answer\n",
    "new = new_answer\n",
    "initial_js = original_js\n",
    "updated_js = new_js\n",
    "change_impact = impact\n",
    "\n",
    "message_content = f\"Using the variables: feature ({feature}), original ({original}), new ({new}), initial job satisfaction ({initial_js:.4f}), updated job satisfaction ({updated_js:.4f}), and change impact ({change_impact:.4f}), construct a readable sentence that describes the most impactful change for improving job satisfaction.\"\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    system=\"Rewrite in flowing English.\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message_content}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bwm_mid16SQA",
    "2LPXAR9X6SQB",
    "v42SoQeD6SQB",
    "xYyQicVr6SQB",
    "K-MMbhAC6SQF"
   ],
   "name": "IMP-PCMLAI-M23-reinforcement-learning-tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
