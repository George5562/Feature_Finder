{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract data\n",
    "data = pd.read_csv('processed_data_final.csv')\n",
    "X = data.drop(columns=['JobSatisfaction_O'])\n",
    "y = data['JobSatisfaction_O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split numerical & text columns, and Fixed & Actionable categories\n",
    "numerical_fixed_columns = [col for col in X.columns if col.endswith('_F') and X[col].dtype == 'float64']\n",
    "numerical_actionable_columns = [col for col in X.columns if col.endswith('_A') and X[col].dtype == 'float64']\n",
    "binary_fixed_columns = [col for col in X.columns if col.endswith('_F') and X[col].dtype == 'int64']\n",
    "binary_actionable_columns = [col for col in X.columns if col.endswith('_A') and X[col].dtype == 'int64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'binary_actionable_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m binary_actionable_groups \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbinary_actionable_columns\u001b[49m:\n\u001b[0;32m      3\u001b[0m     question_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(col\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m question_prefix \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m binary_actionable_groups:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'binary_actionable_columns' is not defined"
     ]
    }
   ],
   "source": [
    "#store questions & answers for binary columns\n",
    "binary_actionable_groups = {}\n",
    "for col in binary_actionable_columns:\n",
    "    question_prefix = '_'.join(col.split('_')[:-2])\n",
    "    if question_prefix not in binary_actionable_groups:\n",
    "        binary_actionable_groups[question_prefix] = []\n",
    "    binary_actionable_groups[question_prefix].append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X[numerical_fixed_columns + numerical_actionable_columns] = scaler.fit_transform(X[numerical_fixed_columns + numerical_actionable_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_info = {\n",
    "    'numerical_fixed_columns': numerical_fixed_columns,\n",
    "    'numerical_actionable_columns': numerical_actionable_columns,\n",
    "    'binary_fixed_columns': binary_fixed_columns,\n",
    "    'binary_actionable_groups': binary_actionable_groups,\n",
    "    'scaler': scaler\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model with dropout layers to reduce overfitting\n",
    "class JobSatisfactionNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(JobSatisfactionNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.dropout1 = nn.Dropout(0.5)  \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)  \n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)  \n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)  \n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JobSatisfactionNN(\n",
       "  (fc1): Linear(in_features=573, out_features=128, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "input_dim = X.shape[1]\n",
    "model = JobSatisfactionNN(input_dim)\n",
    "model.load_state_dict(torch.load('final_model.pth'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to query the impact on job satisfaction that each change in an actionable answer has\n",
    "def sensitivity_analysis(model, X, row_number, preprocessing_info, y):\n",
    "    original_data = X.iloc[row_number:row_number+1].copy()\n",
    "    original_tensor = torch.tensor(original_data.values, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        original_prediction = model(original_tensor).item()\n",
    "\n",
    "    actionable_changes = []\n",
    "\n",
    "    # Numerical Actionable Features\n",
    "    for col in preprocessing_info['numerical_actionable_columns']:\n",
    "        min_value = X[col].min()\n",
    "        max_value = X[col].max()\n",
    "\n",
    "        for new_value in [min_value, max_value]:\n",
    "            modified_data = original_data.copy()\n",
    "            modified_data[col] = new_value\n",
    "            modified_tensor = torch.tensor(modified_data.values, dtype=torch.float32)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                modified_prediction = model(modified_tensor).item()\n",
    "\n",
    "            impact = modified_prediction - original_prediction\n",
    "            actionable_changes.append((col, original_data[col].values[0], new_value, original_prediction, modified_prediction, impact))\n",
    "\n",
    "    # Binary Actionable Features\n",
    "    for group, cols in preprocessing_info['binary_actionable_groups'].items():\n",
    "        for col in cols:\n",
    "            if original_data[col].values[0] == 1:\n",
    "                original_col = col\n",
    "                break\n",
    "        else:\n",
    "            original_col = None\n",
    "\n",
    "        for col in cols:\n",
    "            if col != original_col:\n",
    "                modified_data = original_data.copy()\n",
    "                if original_col:\n",
    "                    modified_data[original_col] = 0\n",
    "                modified_data[col] = 1\n",
    "                modified_tensor = torch.tensor(modified_data.values, dtype=torch.float32)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    modified_prediction = model(modified_tensor).item()\n",
    "\n",
    "                impact = modified_prediction - original_prediction\n",
    "                actionable_changes.append((col, original_data[col].values[0] if original_col else 0, 1, original_prediction, modified_prediction, impact))\n",
    "\n",
    "    actionable_changes.sort(key=lambda x: x[5], reverse=True)\n",
    "    return actionable_changes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: RemoteWork_Always_A, Original Answer: 0, New Answer: 1, Original Job Satisfaction: -0.2621, Predicted New Job Satisfaction: 0.1659, Impact: 0.4280\n",
      "Feature: MLMethodNextYearSelect_Factor Alysis_A, Original Answer: 0, New Answer: 1, Original Job Satisfaction: -0.2621, Predicted New Job Satisfaction: 0.0736, Impact: 0.3357\n",
      "Feature: MLToolNextYearSelect_TIBCO Spotfire_A, Original Answer: 0, New Answer: 1, Original Job Satisfaction: -0.2621, Predicted New Job Satisfaction: 0.0602, Impact: 0.3223\n",
      "Feature: MLToolNextYearSelect_RapidMiner (free version)_A, Original Answer: 0, New Answer: 1, Original Job Satisfaction: -0.2621, Predicted New Job Satisfaction: 0.0027, Impact: 0.2648\n",
      "Feature: LanguageRecommendationSelect_Stata_A, Original Answer: 0, New Answer: 1, Original Job Satisfaction: -0.2621, Predicted New Job Satisfaction: -0.0032, Impact: 0.2588\n"
     ]
    }
   ],
   "source": [
    "row_number = 1001  # Index of the new user\n",
    "top_changes = sensitivity_analysis(model, X, row_number, preprocessing_info, y)\n",
    "\n",
    "# Display top changes\n",
    "for change in top_changes:\n",
    "    print(f\"Feature: {change[0]}, Original Answer: {change[1]}, New Answer: {change[2]}, \"\n",
    "          f\"Original Job Satisfaction: {change[3]:.4f}, Predicted New Job Satisfaction: {change[4]:.4f}, \"\n",
    "          f\"Impact: {change[5]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anthropic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43manthropic\u001b[49m\u001b[38;5;241m.\u001b[39mAnthropic(\n\u001b[0;32m      3\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mANTHROPIC_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      7\u001b[0m top_change \u001b[38;5;241m=\u001b[39m top_changes[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m feature_name \u001b[38;5;241m=\u001b[39m top_change[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtitle()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'anthropic' is not defined"
     ]
    }
   ],
   "source": [
    "#use llm api to re-write the results into natural language \n",
    "import os\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=os.getenv('ANTHROPIC_API_KEY')\n",
    ")\n",
    "\n",
    "\n",
    "top_change = top_changes[0]\n",
    "feature_name = top_change[0].replace('_', ' ').title()\n",
    "original_answer = \"Yes\" if top_change[1] == 1 else \"No\"\n",
    "new_answer = \"Yes\" if top_change[2] == 1 else \"No\"\n",
    "original_js = top_change[3]\n",
    "new_js = top_change[4]\n",
    "impact = top_change[5]\n",
    "\n",
    "\n",
    "feature = feature_name\n",
    "original = original_answer\n",
    "new = new_answer\n",
    "initial_js = original_js\n",
    "updated_js = new_js\n",
    "change_impact = impact\n",
    "\n",
    "message_content = f\"Using the variables: feature ({feature}), original ({original}), new ({new}), initial job satisfaction ({initial_js:.4f}), updated job satisfaction ({updated_js:.4f}), and change impact ({change_impact:.4f}), construct a readable sentence that describes the most impactful change for improving job satisfaction.\"\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    system=\"Rewrite in flowing English.\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message_content}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bwm_mid16SQA",
    "2LPXAR9X6SQB",
    "v42SoQeD6SQB",
    "xYyQicVr6SQB",
    "K-MMbhAC6SQF"
   ],
   "name": "IMP-PCMLAI-M23-reinforcement-learning-tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
